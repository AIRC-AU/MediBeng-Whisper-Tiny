import os
import torch
import torchaudio
import gradio as gr
from transformers import WhisperProcessor, WhisperForConditionalGeneration

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "..", "models", "whisper-tiny")

# ç¡®ä¿æ¨¡å‹è·¯å¾„å­˜åœ¨
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"Model path does not exist: {MODEL_PATH}")

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
try:
    processor = WhisperProcessor.from_pretrained(MODEL_PATH)
    model = WhisperForConditionalGeneration.from_pretrained(MODEL_PATH)
    if torch.cuda.is_available():
        model = model.to("cuda")
        print("ä½¿ç”¨ GPU è¿›è¡Œæ¨ç†")
    else:
        print("ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†")
except Exception as e:
    raise RuntimeError(f"Failed to load model from {MODEL_PATH}: {e}")


def process_audio(audio_file_path):
    """
    ä½¿ç”¨torchaudioç›´æ¥åŠ è½½éŸ³é¢‘ï¼Œå¿½ç•¥å…ƒæ•°æ®ï¼Œå¼ºåˆ¶å¤„ç†ä¸ºæ ‡å‡†æ ¼å¼
    """
    if not os.path.exists(audio_file_path):
        raise FileNotFoundError(f"Audio file not found: {audio_file_path}")

    try:
        # ç›´æ¥ä½¿ç”¨torchaudioåŠ è½½ï¼Œä¸ä¾èµ–ffmpeg
        waveform, sample_rate = torchaudio.load(audio_file_path)

        # é‡é‡‡æ ·åˆ°16kHz
        if sample_rate != 16000:
            resampler = torchaudio.transforms.Resample(
                orig_freq=sample_rate,
                new_freq=16000
            )
            waveform = resampler(waveform)

        # è½¬ä¸ºå•å£°é“
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)

        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        input_features = processor(
            waveform.squeeze().numpy(),
            sampling_rate=16000,
            return_tensors="pt"
        ).input_features

        # ä½¿ç”¨GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            input_features = input_features.to("cuda")

        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            predicted_ids = model.generate(input_features)

        # è§£ç ç»“æœ
        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
        return transcription[0]

    except Exception as e:
        raise RuntimeError(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")


def predict(file):
    """
    Gradioæ¥å£å‡½æ•°ï¼Œå¤„ç†æ–‡ä»¶ä¸Šä¼ 
    """
    if not file:
        return "è¯·ä¸Šä¼ WAVéŸ³é¢‘æ–‡ä»¶"

    try:
        # è·å–ä¸Šä¼ æ–‡ä»¶çš„ä¸´æ—¶è·¯å¾„
        audio_path = file.name
        return process_audio(audio_path)

    except Exception as e:
        return f"é”™è¯¯: {str(e)}"


def create_web_interface():
    """
    åˆ›å»ºGradioç•Œé¢ï¼ˆå®Œå…¨å…¼å®¹ä½ç‰ˆæœ¬Gradioï¼‰
    """
    test_data_dir = os.path.join(BASE_DIR, "..", "tests", "data")
    example_files = []

    # æ£€æŸ¥æ˜¯å¦æœ‰ç¤ºä¾‹æ–‡ä»¶
    if os.path.exists(test_data_dir):
        wav_files = [f for f in os.listdir(test_data_dir) if f.lower().endswith('.wav')]
        if wav_files:
            example_files = [os.path.join(test_data_dir, f) for f in wav_files[:2]]

    with gr.Blocks(title="Whisper éŸ³é¢‘è½¬å½•") as interface:
        gr.Markdown("## Whisper éŸ³é¢‘è½¬å½•ç³»ç»Ÿ")

        # ä½¿ç”¨Markdownæ›¿ä»£descriptionå‚æ•°æä¾›è¯¦ç»†è¯´æ˜
        gr.Markdown("""
        ğŸš¨ **é‡è¦æç¤º**  
        - ä»…æ”¯æŒ **WAV æ ¼å¼** æ–‡ä»¶ï¼ˆ.wavï¼‰  
        - ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†é‡‡æ ·ç‡ï¼ˆå»ºè®®16kHzï¼‰å’Œå£°é“æ•°  
        - æ— éœ€å®‰è£…ffmpegï¼Œæ‰€æœ‰å¤„ç†å‡åœ¨Pythonä¸­å®Œæˆ  
        """)

        with gr.Row():
            with gr.Column(scale=1):
                # ä»…ä½¿ç”¨å¿…è¦å‚æ•°ï¼Œé¿å…ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜
                file_input = gr.File(
                    label="ä¸Šä¼ éŸ³é¢‘",
                    file_types=[".wav"]
                )
                submit_btn = gr.Button("å¼€å§‹è½¬å½•")

                gr.Markdown("### ç¤ºä¾‹éŸ³é¢‘")
                if example_files:
                    # ç›´æ¥ä¼ é€’å®Œæ•´è·¯å¾„ï¼Œä¾èµ–Gradioè‡ªåŠ¨å¤„ç†
                    gr.Examples(
                        examples=example_files,
                        inputs=file_input,
                        cache_examples=False
                    )
                else:
                    gr.Markdown("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶")

            with gr.Column(scale=2):
                text_output = gr.Textbox(label="è½¬å½•ç»“æœ", lines=10)

        submit_btn.click(
            fn=predict,
            inputs=file_input,
            outputs=text_output
        )

        # åº•éƒ¨æ·»åŠ é¢å¤–è¯´æ˜
        gr.Markdown("""
        ### æŠ€æœ¯ç»†èŠ‚  
        - æ¨¡å‹: Whisper Tiny  
        - æ¨ç†è®¾å¤‡: {}  
        - æ”¯æŒè¯­è¨€: ä¸»è¦æ”¯æŒè‹±è¯­ï¼ˆå¯é€šè¿‡æ›´æ¢æ¨¡å‹æ‰©å±•ï¼‰  
        """.format("GPU" if torch.cuda.is_available() else "CPU"))

    return interface


if __name__ == "__main__":
    interface = create_web_interface()
    interface.launch(share=False)